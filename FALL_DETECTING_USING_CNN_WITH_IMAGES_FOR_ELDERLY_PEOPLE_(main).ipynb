{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gkulatheja/g_kulatheja/blob/master/FALL_DETECTING_USING_CNN_WITH_IMAGES_FOR_ELDERLY_PEOPLE_(main).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPN8OMJkkEZq",
        "outputId": "f0626ae6-b5a8-46a2-95ff-714418d4dd28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.67.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy pandas tensorflow scikit-learn pillow matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "hQ-6wC1ihAxQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c8w7o9Jo2Dn",
        "outputId": "57c57086-df90-4477-f339-039f92f9b560"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.49-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2024.8.30)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.26.4)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (11.0.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.2.3)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.6)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.3.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.54.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.4.0)\n",
            "Downloading roboflow-1.1.49-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: filetype, python-dotenv, idna, roboflow\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "Successfully installed filetype-1.2.0 idna-3.7 python-dotenv-1.0.1 roboflow-1.1.49\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in Fall-Detection-4 to coco:: 100%|██████████| 527197/527197 [00:14<00:00, 35809.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Fall-Detection-4 in coco:: 100%|██████████| 10794/10794 [00:04<00:00, 2261.80it/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"ggyfNCLR8mH4U0ZjKozm\")\n",
        "project = rf.workspace(\"roboflow-universe-projects\").project(\"fall-detection-ca3o8\")\n",
        "version = project.version(4)\n",
        "dataset = version.download(\"coco\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "fdYfhkv4jsVS",
        "outputId": "79b617be-d0b2-48a2-b2eb-069b9dc31203"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-599c079e-edda-4226-8076-55ba3cdb4751\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-599c079e-edda-4226-8076-55ba3cdb4751\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving Fall.zip to Fall.zip\n",
            "Extracted 'Fall.zip' to '/content/'\n",
            "Extracted folder contents:\n",
            "['test_images', 'train_labels.csv', 'train_images', 'test_labels.csv']\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Step 1: Compress your folder into a zip file\n",
        "# For example, if your folder is named \"my_images\", compress it to \"my_images.zip\" on your local machine.\n",
        "\n",
        "# Step 2: Upload the zip file to Colab\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Step 3: Unzip the uploaded folder\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.zip'):\n",
        "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "            zip_ref.extractall('/content/')\n",
        "        print(f\"Extracted '{filename}' to '/content/'\")\n",
        "\n",
        "# Optional: List the contents of the extracted folder to confirm\n",
        "extracted_folder = filename.replace('.zip', '')\n",
        "print(\"Extracted folder contents:\")\n",
        "print(os.listdir(f\"/content/{extracted_folder}\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886
        },
        "id": "ihmXjvBFjLzZ",
        "outputId": "ae9d3bb1-11a3-4a64-f148-71a3927ac78e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6184 - loss: 0.6062 - val_accuracy: 1.0000 - val_loss: 0.2391\n",
            "Epoch 2/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 897ms/step - accuracy: 0.9380 - loss: 0.2213 - val_accuracy: 1.0000 - val_loss: 0.0364\n",
            "Epoch 3/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.9548 - loss: 0.1017 - val_accuracy: 1.0000 - val_loss: 0.0164\n",
            "Epoch 4/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 874ms/step - accuracy: 0.9682 - loss: 0.0907 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
            "Epoch 5/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.9876 - loss: 0.0405 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
            "Epoch 6/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.9988 - loss: 0.0180 - val_accuracy: 1.0000 - val_loss: 0.0068\n",
            "Epoch 7/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 889ms/step - accuracy: 0.9932 - loss: 0.0282 - val_accuracy: 1.0000 - val_loss: 7.1021e-05\n",
            "Epoch 8/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.9932 - loss: 0.0159 - val_accuracy: 1.0000 - val_loss: 2.0188e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.9906 - loss: 0.0283 - val_accuracy: 1.0000 - val_loss: 1.2444e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 882ms/step - accuracy: 0.9933 - loss: 0.0140 - val_accuracy: 1.0000 - val_loss: 4.0017e-04\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.9167 - loss: 0.1115\n",
            "Test accuracy: 91.67%\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Parameters\n",
        "image_size = (128, 128)  # Set desired image size\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "# Paths to train and test CSV files and image folders\n",
        "train_csv_path = '/content/Fall/train_labels.csv'  # Adjust the path\n",
        "test_csv_path = '/content/Fall/test_labels.csv'    # Adjust the path\n",
        "train_image_dir = '/content/Fall/train_images'  # Adjust the path\n",
        "test_image_dir = '/content/Fall/test_images'    # Adjust the path\n",
        "\n",
        "# Load the train and test CSV files\n",
        "train_df = pd.read_csv(train_csv_path)\n",
        "test_df = pd.read_csv(test_csv_path)\n",
        "\n",
        "# Function to load images and labels from CSV file\n",
        "def load_data(dataframe, image_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for index, row in dataframe.iterrows():\n",
        "        img_path = os.path.join(image_dir, row['images'])\n",
        "        if os.path.exists(img_path):\n",
        "            img = Image.open(img_path).resize(image_size)\n",
        "            images.append(np.array(img))\n",
        "            labels.append(row['labels'])\n",
        "    images = np.array(images) / 255.0  # Normalize pixel values\n",
        "    labels = np.array(labels)          # Convert labels to numpy array\n",
        "    return images, labels\n",
        "\n",
        "# Load training and testing data\n",
        "X_train, y_train = load_data(train_df, train_image_dir)\n",
        "X_test, y_test = load_data(test_df, test_image_dir)\n",
        "\n",
        "# Define the CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')  # Single output neuron with sigmoid activation for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Plot training history\n",
        "plt.plot(history.history['accuracy'], label='train_accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC0KAXqXmQUf",
        "outputId": "603d4262-5614-4045-ef13-ec83c20fe507"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Prediction: Fall detected.\n",
            "Fall alert email with image sent successfully.\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import smtplib\n",
        "import os\n",
        "from email.message import EmailMessage\n",
        "import ssl\n",
        "\n",
        "# Function to preprocess the image\n",
        "def preprocess_image(img_path, image_size=(128, 128)):\n",
        "    img = Image.open(img_path)\n",
        "    img = img.resize(image_size)  # Resize image to match the input shape of the model\n",
        "    img_array = np.array(img) / 255.0  # Normalize the image\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    return img_array, img  # Return both the array and the original resized image\n",
        "\n",
        "# Function to send an email with the image attachment\n",
        "def send_fall_alert(image_path):\n",
        "    # Email credentials\n",
        "    email_address = \"ambatijayacharan18@gmail.com\"\n",
        "    email_password = \"jnzu ewoa orde weyx\"\n",
        "    guardian_email = \"99220041224@klu.ac.in\"\n",
        "\n",
        "    # Create the email message\n",
        "    msg = EmailMessage()\n",
        "    msg['Subject'] = \"Fall Detected Alert!\"\n",
        "    msg['From'] = email_address\n",
        "    msg['To'] = guardian_email\n",
        "    msg.set_content(\"A fall has been detected. Please check on the individual immediately.\\nThe attached image shows the detected fall.\")\n",
        "\n",
        "    # Attach the image\n",
        "    with open(image_path, 'rb') as img_file:\n",
        "        img_data = img_file.read()\n",
        "        msg.add_attachment(img_data, maintype='image', subtype='jpeg', filename='fall_detected.jpg')\n",
        "\n",
        "    try:\n",
        "        # Establish a secure session with Gmail's SMTP server\n",
        "        context = ssl.create_default_context()\n",
        "        with smtplib.SMTP_SSL('smtp.gmail.com', 465, context=context) as server:\n",
        "            server.login(email_address, email_password)\n",
        "            server.send_message(msg)\n",
        "            print(\"Fall alert email with image sent successfully.\")\n",
        "    except smtplib.SMTPAuthenticationError:\n",
        "        print(\"Authentication error: Check your email credentials.\")\n",
        "        print(\"If you have 2-Step Verification enabled, use an App Password instead.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Path to the new image for prediction\n",
        "new_image_path = '/content/Fall/test_images/fall-03-cam1-rgb-196.jpg'  # Adjust the path as needed\n",
        "\n",
        "# Preprocess the image\n",
        "preprocessed_image, resized_image = preprocess_image(new_image_path)\n",
        "\n",
        "# Save the resized image temporarily\n",
        "temp_image_path = '/content/temp_fall_image.jpg'\n",
        "resized_image.save(temp_image_path)\n",
        "\n",
        "# Make a prediction\n",
        "prediction = model.predict(preprocessed_image)\n",
        "\n",
        "# Interpret the prediction and send an alert if a fall is detected\n",
        "if prediction[0][0] > 0.5:\n",
        "    print(\"Prediction: Fall detected.\")\n",
        "    send_fall_alert(temp_image_path)  # Send email notification with the image\n",
        "else:\n",
        "    print(\"Prediction: Not Fall.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNrEFVkSqEOp",
        "outputId": "1e8fc203-0b12-400e-841d-b6e79538a77b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Epoch 1/10\n",
            "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2920s\u001b[0m 5s/step - accuracy: 0.9890 - loss: 0.0102 - val_accuracy: 1.0000 - val_loss: 1.0459e-08\n",
            "Epoch 2/10\n",
            "\u001b[1m  1/590\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:59\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 4.2361e-09"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.2361e-09 - val_accuracy: 1.0000 - val_loss: 8.3044e-09\n",
            "Epoch 3/10\n",
            "\u001b[1m247/590\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m25:13\u001b[0m 4s/step - accuracy: 1.0000 - loss: 1.1021e-08"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import json\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Enable mixed precision if GPU allows\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Load COCO annotations\n",
        "def load_coco_data(annotation_file):\n",
        "    with open(annotation_file, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    return data\n",
        "\n",
        "# Optimized data pipeline\n",
        "def preprocess_coco_dataset(data, image_dir, label_map, img_size=(224, 224), batch_size=16):\n",
        "    def process_annotation(annotation):\n",
        "        image_id = annotation['image_id']\n",
        "        label = label_map[annotation['category_id']]\n",
        "        image_info = next(item for item in data['images'] if item['id'] == image_id)\n",
        "        image_path = os.path.join(image_dir, image_info['file_name'])\n",
        "\n",
        "        # Load and preprocess image\n",
        "        img = tf.keras.preprocessing.image.load_img(image_path, target_size=img_size)\n",
        "        img = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
        "        return img, label\n",
        "\n",
        "    dataset = tf.data.Dataset.from_generator(\n",
        "        lambda: (process_annotation(ann) for ann in data['annotations']),\n",
        "        output_signature=(\n",
        "            tf.TensorSpec(shape=(224, 224, 3), dtype=tf.float32),\n",
        "            tf.TensorSpec(shape=(), dtype=tf.int32)\n",
        "        )\n",
        "    )\n",
        "    return dataset.batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Paths to datasets and COCO annotation files\n",
        "train_annotation_file = '/content/Fall-Detection-4/train/_annotations.coco.json'\n",
        "valid_annotation_file = '/content/Fall-Detection-4/valid/_annotations.coco.json'\n",
        "train_image_dir = '/content/Fall-Detection-4/train'\n",
        "valid_image_dir = '/content/Fall-Detection-4/valid'\n",
        "\n",
        "# Define label map (adjust as needed)\n",
        "label_map = {1: 1, 0: 0}  # Example: {fall: 1, no fall: 0}\n",
        "\n",
        "# Load and preprocess datasets\n",
        "train_data = load_coco_data(train_annotation_file)\n",
        "valid_data = load_coco_data(valid_annotation_file)\n",
        "\n",
        "batch_size = 16\n",
        "train_dataset = preprocess_coco_dataset(train_data, train_image_dir, label_map, batch_size=batch_size)\n",
        "valid_dataset = preprocess_coco_dataset(valid_data, valid_image_dir, label_map, batch_size=batch_size)\n",
        "\n",
        "steps_per_epoch = len(train_data['annotations']) // batch_size\n",
        "validation_steps = len(valid_data['annotations']) // batch_size\n",
        "\n",
        "# Define CNN model using transfer learning with ResNet50\n",
        "def create_model():\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    base_model.trainable = False  # Freeze the base model\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(256, activation='relu')(x)  # Reduced complexity\n",
        "    predictions = Dense(1, activation='sigmoid', dtype='float32')(x)  # Set dtype to float32\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model with early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "history = model.fit(train_dataset, validation_data=valid_dataset, epochs=10,  # Reduced max epochs\n",
        "                    steps_per_epoch=steps_per_epoch, validation_steps=validation_steps,\n",
        "                    callbacks=[early_stopping])\n",
        "\n",
        "# Plot training accuracy and loss\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}